{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "31763d61",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-10-23 21:33:42.174\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mvaluation.asset.dataset.base\u001b[0m:\u001b[36mload\u001b[0m:\u001b[36m338\u001b[0m - \u001b[34m\u001b[1mDataset Dataset train_val of the model stage created on 2025-10-23 at 21:11 loaded.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Frequency check for a sample series:\n",
      "ds\n",
      "7 days     304\n",
      "35 days      1\n",
      "21 days      1\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Expected number of weeks in train_df (approx): 313\n",
      "\n",
      "Checking completeness per series:\n",
      "                            min        max  count\n",
      "unique_id                                        \n",
      "100_analgesics       1990-01-03 1995-12-27    307\n",
      "100_bath soap        1992-02-26 1995-12-27    195\n",
      "100_bathroom tissues 1990-01-03 1995-12-27    303\n",
      "100_beer             1991-06-12 1995-12-27    232\n",
      "100_bottled juices   1990-01-03 1995-12-27    307\n",
      "\n",
      "Found 1924 series with potentially missing periods:\n",
      "                            min        max  count\n",
      "unique_id                                        \n",
      "100_analgesics       1990-01-03 1995-12-27    307\n",
      "100_bath soap        1992-02-26 1995-12-27    195\n",
      "100_bathroom tissues 1990-01-03 1995-12-27    303\n",
      "100_beer             1991-06-12 1995-12-27    232\n",
      "100_bottled juices   1990-01-03 1995-12-27    307\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "from valuation.asset.identity.dataset import DatasetID\n",
    "from valuation.core.stage import DatasetStage\n",
    "from valuation.infra.store.dataset import DatasetStore\n",
    "store = DatasetStore()\n",
    "dataset_id = DatasetID(name=\"train_val\", stage=DatasetStage.MODEL)\n",
    "passport = store.get_passport(dataset_id=dataset_id)\n",
    "ds = store.get(passport=passport)\n",
    "train_df = ds.data\n",
    "# Check frequency of the 'ds' column in your train_df\n",
    "# Calculate the difference between consecutive dates for a sample series\n",
    "sample_id = train_df['unique_id'].iloc[0]\n",
    "sample_series_dates = train_df[train_df['unique_id'] == sample_id]['ds'].sort_values()\n",
    "date_diffs = sample_series_dates.diff().dropna()\n",
    "\n",
    "print(\"Frequency check for a sample series:\")\n",
    "print(date_diffs.value_counts())\n",
    "\n",
    "# Check for missing periods per series\n",
    "completeness_check = train_df.groupby('unique_id')['ds'].agg(['min', 'max', 'count'])\n",
    "expected_weeks_train = (train_df['ds'].max() - train_df['ds'].min()).days // 7 + 1 # Approximate for 6 years\n",
    "\n",
    "print(f\"\\nExpected number of weeks in train_df (approx): {expected_weeks_train}\")\n",
    "print(\"\\nChecking completeness per series:\")\n",
    "print(completeness_check.head())\n",
    "\n",
    "# Find series that don't have the expected number of weeks\n",
    "incomplete_series = completeness_check[completeness_check['count'] != expected_weeks_train]\n",
    "if not incomplete_series.empty:\n",
    "    print(f\"\\nFound {len(incomplete_series)} series with potentially missing periods:\")\n",
    "    print(incomplete_series.head())\n",
    "else:\n",
    "    print(\"\\nAll series appear to have the expected number of periods.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93f12291",
   "metadata": {},
   "source": [
    "## History per Series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5a2c71f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Series length distribution:\n",
      "count    2403.000000\n",
      "mean      280.491469\n",
      "std        52.452566\n",
      "min        30.000000\n",
      "25%       237.000000\n",
      "50%       312.000000\n",
      "75%       312.000000\n",
      "max       312.000000\n",
      "Name: weeks, dtype: float64\n",
      "\n",
      "Series with < 260 weeks: 664\n",
      "Series with >= 260 weeks: 1,739\n"
     ]
    }
   ],
   "source": [
    "# How much history do you have per series?\n",
    "series_length = train_df.groupby('unique_id')['ds'].agg(['min', 'max', 'count'])\n",
    "series_length['weeks'] = (series_length['max'] - series_length['min']).dt.days / 7\n",
    "\n",
    "print(\"Series length distribution:\")\n",
    "print(series_length['weeks'].describe())\n",
    "print(f\"\\nSeries with < 260 weeks: {(series_length['weeks'] < 260).sum():,}\")\n",
    "print(f\"Series with >= 260 weeks: {(series_length['weeks'] >= 260).sum():,}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "valuation",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
