{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "43cb608e",
   "metadata": {},
   "source": [
    "# LightGBM Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "623f8049",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/john/anaconda3/envs/valuation/lib/python3.12/site-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'repr' attribute with value False was provided to the `Field()` function, which has no effect in the context it was used. 'repr' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.\n",
      "  warnings.warn(\n",
      "/home/john/anaconda3/envs/valuation/lib/python3.12/site-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'frozen' attribute with value True was provided to the `Field()` function, which has no effect in the context it was used. 'frozen' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.\n",
      "  warnings.warn(\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33maistudio\u001b[0m to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from lightgbm import LGBMRegressor # The ML model\n",
    "\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import polars as pl\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "import wandb\n",
    "from sklearn.pipeline import FunctionTransformer\n",
    "\n",
    "\n",
    "from hierarchicalforecast.core import HierarchicalReconciliation\n",
    "from hierarchicalforecast.methods import MinTrace, BottomUp\n",
    "from hierarchicalforecast.utils import aggregate\n",
    "from hierarchicalforecast.core import HierarchicalReconciliation\n",
    "from mlforecast import MLForecast\n",
    "\n",
    "from valuation.infra.store.dataset import DatasetStore\n",
    "from valuation.asset.identity.dataset import DatasetID\n",
    "from valuation.core.stage import DatasetStage\n",
    "from valuation.asset.identity.model import ModelPassport\n",
    "\n",
    "\n",
    "from valuation.flow.modeling.model_selection.light_gbm import LightGBMHP\n",
    "from valuation.flow.modeling.model_selection.cv import CrossValidationHP\n",
    "from valuation.flow.modeling.model_selection.mlforecast import MLForecastHP\n",
    "from valuation.flow.modeling.model_selection.base import ModelParams\n",
    "from valuation.infra.store.model import ModelStore\n",
    "from valuation.asset.model.mlforecast import MLForecastModel\n",
    "from valuation.core.stage import ModelStage\n",
    "\n",
    "\n",
    "# Suppress the specific warning\n",
    "warnings.filterwarnings('ignore', message='.*lag.*')\n",
    "warnings.filterwarnings('ignore', message='.*UnsupportedFieldAttributeWarning.*')\n",
    "wandb.login()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bc1866f",
   "metadata": {},
   "source": [
    "## Model Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "74bcf1c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "                     ModelParams.light_gbm                      \n",
      "================================================================\n",
      "                       verbosity | -1\n",
      "                       objective | tweedie\n",
      "          tweedie_variance_power | 1.2\n",
      "                    n_estimators | 1000\n",
      "                   learning_rate | 0.02\n",
      "                       max_depth | 7\n",
      "                      num_leaves | 63\n",
      "               min_child_samples | 20\n",
      "                       subsample | 0.8\n",
      "                colsample_bytree | 0.7\n",
      "                       reg_alpha | 1.0\n",
      "                      reg_lambda | 1.0\n",
      "                  subsample_freq | 1\n",
      "                  min_split_gain | 0.1\n",
      "                min_child_weight | 1.0\n",
      "                    random_state | 42\n",
      "                          n_jobs | 22\n",
      "\n",
      "\n",
      "                     ModelParams.mlforecast                     \n",
      "================================================================\n",
      "                            freq | W-WED\n",
      "                     num_threads | 22\n",
      "\n",
      "\n",
      "                  ModelParams.cross_validation                  \n",
      "================================================================\n",
      "                               h | 26\n",
      "                       n_windows | 3\n",
      "                       step_size | 13\n",
      "                          fitted | True\n",
      "                          dropna | True\n",
      "\n"
     ]
    }
   ],
   "source": [
    "NUM_CORES = 24              # Total CPU cores available\n",
    "# Reproducibility \n",
    "RANDOM_STATE = 42           # Fixed random seed\n",
    "\n",
    "# Create the FunctionTransformer \n",
    "log_transformer = FunctionTransformer(\n",
    "    func=np.log1p,\n",
    "    inverse_func=np.expm1,\n",
    "    # Required for API compatibility in mlforecast target_transforms\n",
    "    feature_names_out=\"one-to-one\",\n",
    "    # Removed the deprecated 'check_input=False'\n",
    ")\n",
    "\n",
    "# LightGBM model parameters\n",
    "lightgbm_params = LightGBMHP(\n",
    "    objective='tweedie',\n",
    "    tweedie_variance_power=1.2,\n",
    "    n_estimators=1000,\n",
    "    learning_rate=0.02,\n",
    "    reg_alpha=1.0,\n",
    "    reg_lambda=1.0,\n",
    "    subsample=0.8,\n",
    "    max_depth=7\n",
    "    )      # See the dataclass for details on defaults\n",
    "\n",
    "# MLForecast parameters\n",
    "mlforecast_params = MLForecastHP(\n",
    "    lags=[1,2,4,13,52,43],\n",
    "    )  # See the dataclass for details on defaults\n",
    "\n",
    "# Cross-validation parameters\n",
    "cross_validation_params = CrossValidationHP()  # See the dataclass for details on defaults\n",
    "\n",
    "# Combine all model parameters\n",
    "model_params = ModelParams(\n",
    "    light_gbm=lightgbm_params,\n",
    "    mlforecast=mlforecast_params,\n",
    "    cross_validation=cross_validation_params\n",
    ")\n",
    "print(model_params)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a8b4d57",
   "metadata": {},
   "source": [
    "## Register the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9d965207",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.22.2"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/john/projects/valuation/wandb/run-20251025_181523-stb5sreu</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/aistudio/valuation/runs/stb5sreu' target=\"_blank\">proud-firebrand-30</a></strong> to <a href='https://wandb.ai/aistudio/valuation' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/aistudio/valuation' target=\"_blank\">https://wandb.ai/aistudio/valuation</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/aistudio/valuation/runs/stb5sreu' target=\"_blank\">https://wandb.ai/aistudio/valuation/runs/stb5sreu</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "run = wandb.init(project=\"valuation\", job_type=\"modeling\")\n",
    "run.config.update(lightgbm_params.as_dict())\n",
    "run.config.update(mlforecast_params.as_dict())\n",
    "run.config.update(cross_validation_params.as_dict())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35da959f",
   "metadata": {},
   "source": [
    "## Training Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d9ce279e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-10-25 18:15:24.808\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mvaluation.infra.file.io.fast\u001b[0m:\u001b[36m_read\u001b[0m:\u001b[36m914\u001b[0m - \u001b[34m\u001b[1mReading JSON file: /home/john/projects/valuation/asset_store/prod/dataset/dataset_train_sales_train_val_passport.json\u001b[0m\n",
      "\u001b[32m2025-10-25 18:15:24.816\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mvaluation.infra.file.io.fast\u001b[0m:\u001b[36m_read\u001b[0m:\u001b[36m664\u001b[0m - \u001b[34m\u001b[1mReading fastio parquet file: /home/john/projects/valuation/data/prod/train/dataset_train_sales_train_val.parquet\u001b[0m\n",
      "\u001b[32m2025-10-25 18:15:24.820\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mvaluation.asset.dataset\u001b[0m:\u001b[36mload\u001b[0m:\u001b[36m367\u001b[0m - \u001b[34m\u001b[1mDataset Dataset sales_train_val of the train stage created on 2025-10-25 at 16:56 loaded.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "store = DatasetStore()\n",
    "dataset_id = DatasetID(name=\"sales_train_val\", stage=DatasetStage.TRAIN)\n",
    "passport = store.get_passport(dataset_id=dataset_id)\n",
    "ds = store.get(passport=passport)\n",
    "if isinstance(ds.data, pl.LazyFrame):\n",
    "    train_df = ds.data.collect()\n",
    "else:\n",
    "    train_df = ds.data\n",
    "train_df = train_df.to_pandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9c54a5d",
   "metadata": {},
   "source": [
    "## Define the Model\n",
    "We instantate a LightGBM Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fb693aac",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "models = [LGBMRegressor(**lightgbm_params.as_dict())]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fab67fc5",
   "metadata": {},
   "source": [
    "## Set Cross Validation Lag Parameters from Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e206bd5",
   "metadata": {},
   "source": [
    "## Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b3e68cb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "mf = MLForecast(\n",
    "    models=models,**mlforecast_params.as_dict())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88113e58",
   "metadata": {},
   "source": [
    "## Blocked Cross-Validation\n",
    "This generates the unreconciled forecasts for each fold. We must add fitted=True to get the in-sample forecasts for the reconciler."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "be524319",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MLForecast(models=[LGBMRegressor], freq=W-WED, lag_features=['lag1', 'lag2', 'lag4', 'lag13', 'lag52', 'lag43', 'rolling_mean_lag1_window_size4', 'rolling_mean_lag1_window_size13', 'rolling_mean_lag52_window_size5'], date_features=['week', 'month', 'dayofyear'], num_threads=22)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv_df_base = mf.cross_validation(\n",
    "    df=train_df, **cross_validation_params.as_dict())\n",
    "mf.fit(df=train_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9337fa88",
   "metadata": {},
   "source": [
    "## Create and Persist the Model Object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "02b04f59",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model_store = ModelStore()\n",
    "directory = model_store.file_system.get_asset_stage_location(stage=ModelStage.FINAL) \n",
    "path = directory / f\"lightgbm_model_with_tweedie_variance_power_{lightgbm_params.tweedie_variance_power}/\"\n",
    "mf.save(path=str(path))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e858377",
   "metadata": {},
   "source": [
    "## Create Summing Matrix and Tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b9919aa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Start with the core data (unique_id, ds, y)\n",
    "hierarchy_df = train_df[['unique_id', 'ds', 'y']].drop_duplicates() \n",
    "\n",
    "# 2. Create the grouping columns\n",
    "hierarchy_df['store'] = hierarchy_df['unique_id'].apply(lambda s: s.split('_')[0])\n",
    "hierarchy_df['category'] = hierarchy_df['unique_id'].apply(lambda s: s.split('_')[1])\n",
    "\n",
    "# 3. Drop the 'unique_id' column from the input DF before aggregation\n",
    "#    The aggregate function knows to use the combination of columns in 'spec'\n",
    "#    to uniquely identify the time series levels.\n",
    "hierarchy_df_clean = hierarchy_df.drop(columns=['unique_id']) # üëà ADD THIS LINE\n",
    "\n",
    "spec = [['store'], ['category'], ['store', 'category']]\n",
    "\n",
    "# Pass the cleaned DataFrame to the aggregate function\n",
    "_, S_df, tags = aggregate(df=hierarchy_df_clean, spec=spec)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a24b160d",
   "metadata": {},
   "source": [
    "## Aggregate Forecasts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "16c822b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Forecasts aggregated successfully across all hierarchy levels.\n",
      "Base forecasts shape: (202800, 3)\n",
      "Aggregated forecasts shape: (126828, 3)\n",
      "Unique IDs in aggregated forecasts: 2439\n"
     ]
    }
   ],
   "source": [
    "# Clean and Prepare Y_hat_df_base\n",
    "Y_hat_df_base = cv_df_base.drop(columns=['cutoff', 'y'], errors='ignore')\n",
    "\n",
    "# 1. Add the hierarchy columns to the base forecasts\n",
    "Y_hat_df_base_clean = Y_hat_df_base.copy()\n",
    "Y_hat_df_base_clean['store'] = Y_hat_df_base_clean['unique_id'].apply(lambda s: s.split('_')[0])\n",
    "Y_hat_df_base_clean['category'] = Y_hat_df_base_clean['unique_id'].apply(lambda s: s.split('_')[1])\n",
    "\n",
    "# 2. Identify the forecast column(s) - typically 'LGBMRegressor' or similar model name\n",
    "forecast_col = 'LGBMRegressor'  # Adjust if your column has a different name\n",
    "\n",
    "# 3. Rename forecast column to 'y' temporarily for aggregation\n",
    "Y_hat_df_base_for_agg = Y_hat_df_base_clean.copy()\n",
    "Y_hat_df_base_for_agg = Y_hat_df_base_for_agg.rename(columns={forecast_col: 'y'})\n",
    "Y_hat_df_base_for_agg = Y_hat_df_base_for_agg.drop(columns=['unique_id'])\n",
    "\n",
    "# 4. Aggregate to create forecasts at all hierarchy levels\n",
    "Y_hat_aggregated, _, _ = aggregate(df=Y_hat_df_base_for_agg, spec=spec)\n",
    "\n",
    "# 5. Rename back to original forecast column name\n",
    "Y_hat_aggregated = Y_hat_aggregated.rename(columns={'y': forecast_col})\n",
    "\n",
    "print(\"Forecasts aggregated successfully across all hierarchy levels.\")\n",
    "print(f\"Base forecasts shape: {Y_hat_df_base.shape}\")\n",
    "print(f\"Aggregated forecasts shape: {Y_hat_aggregated.shape}\")\n",
    "print(f\"Unique IDs in aggregated forecasts: {Y_hat_aggregated['unique_id'].nunique()}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75bc6e33",
   "metadata": {},
   "source": [
    "## Reconciler for CV Forecasts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0cfff44e",
   "metadata": {},
   "outputs": [],
   "source": [
    "reconcilers = [MinTrace(method='ols')]\n",
    "hrec = HierarchicalReconciliation(reconcilers=reconcilers)\n",
    "\n",
    "# Prepare aggregated actuals\n",
    "Y_df_base = cv_df_base[['unique_id', 'ds', 'y']].copy()\n",
    "Y_df_base['store'] = Y_df_base['unique_id'].apply(lambda s: s.split('_')[0])\n",
    "Y_df_base['category'] = Y_df_base['unique_id'].apply(lambda s: s.split('_')[1])\n",
    "Y_df_base_for_agg = Y_df_base.drop(columns=['unique_id'])\n",
    "Y_df_actuals, _, _ = aggregate(df=Y_df_base_for_agg, spec=spec)\n",
    "\n",
    "# Reconcile (this adjusts the aggregated forecasts for coherence)\n",
    "cv_df_reconciled = hrec.reconcile(\n",
    "    Y_hat_df=Y_hat_aggregated,  # Now has all hierarchy levels\n",
    "    Y_df=Y_df_actuals,\n",
    "    S_df=S_df,\n",
    "    tags=tags\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1f42215",
   "metadata": {},
   "source": [
    "## Evaluate CV Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3ad9ba1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "\n",
      "                     ModelParams.light_gbm                      \n",
      "================================================================\n",
      "                       verbosity | -1\n",
      "                       objective | tweedie\n",
      "          tweedie_variance_power | 1.2\n",
      "                    n_estimators | 1000\n",
      "                   learning_rate | 0.02\n",
      "                       max_depth | 7\n",
      "                      num_leaves | 63\n",
      "               min_child_samples | 20\n",
      "                       subsample | 0.8\n",
      "                colsample_bytree | 0.7\n",
      "                       reg_alpha | 1.0\n",
      "                      reg_lambda | 1.0\n",
      "                  subsample_freq | 1\n",
      "                  min_split_gain | 0.1\n",
      "                min_child_weight | 1.0\n",
      "                    random_state | 42\n",
      "                          n_jobs | 22\n",
      "\n",
      "\n",
      "                     ModelParams.mlforecast                     \n",
      "================================================================\n",
      "                            freq | W-WED\n",
      "                     num_threads | 22\n",
      "\n",
      "\n",
      "                  ModelParams.cross_validation                  \n",
      "================================================================\n",
      "                               h | 26\n",
      "                       n_windows | 3\n",
      "                       step_size | 13\n",
      "                          fitted | True\n",
      "                          dropna | True\n",
      "\n",
      "Found model columns: ['LGBMRegressor', 'LGBMRegressor/MinTrace_method-ols']\n",
      "\n",
      "Dataset overview:\n",
      "  Total forecasts: 126,828\n",
      "  Unique series: 2,439\n",
      "  Date range: 1995-01-04 00:00:00 to 1995-12-27 00:00:00\n",
      "\n",
      "Actual values summary:\n",
      "count    1.268280e+05\n",
      "mean     8.254113e+03\n",
      "std      4.382746e+04\n",
      "min      0.000000e+00\n",
      "25%      1.800000e+01\n",
      "50%      1.555065e+03\n",
      "75%      4.350370e+03\n",
      "max      1.903111e+06\n",
      "Name: y, dtype: float64\n",
      "\n",
      "================================================================================\n",
      "OVERALL PERFORMANCE (All Hierarchy Levels)\n",
      "================================================================================\n",
      "                              MSE          RMSE          MAE          MAPE   SMAPE       WAPE  Mean_Actual  n_forecasts\n",
      "model                                                                                                                  \n",
      "LGBMRegressor        3.478412e+08  18650.500421  2213.166857  2.944995e+20  70.707  26.812897  8254.113063       126828\n",
      "MinTrace_method-ols  3.478412e+08  18650.500421  2213.166857  2.944995e+20  70.707  26.812897  8254.113063       126828\n",
      "\n",
      "================================================================================\n",
      "PERFORMANCE BY HIERARCHY LEVEL\n",
      "================================================================================\n",
      "\n",
      "STORE_CATEGORY Level:\n",
      "  Unique series: 2,321\n",
      "  Total forecasts: 120,692\n",
      "  Actual mean: 2891.25, std: 4355.31\n",
      "    LGBMRegressor                  -> RMSE:    2769.42, MAE:     979.98, MAPE: 154863945707425595392.00%, Norm_MAE:  33.89%\n",
      "    MinTrace_method-ols            -> RMSE:    2769.42, MAE:     979.98, MAPE: 154863945707425595392.00%, Norm_MAE:  33.89%\n",
      "\n",
      "STORE Level:\n",
      "  Unique series: 93\n",
      "  Total forecasts: 4,836\n",
      "  Actual mean: 72156.92, std: 45682.03\n",
      "    LGBMRegressor                  -> RMSE:   18803.68, MAE:   12480.36, MAPE: 656736425478486491136.00%, Norm_MAE:  17.30%\n",
      "    MinTrace_method-ols            -> RMSE:   18803.68, MAE:   12480.36, MAPE: 656736425478486228992.00%, Norm_MAE:  17.30%\n",
      "\n",
      "CATEGORY Level:\n",
      "  Unique series: 25\n",
      "  Total forecasts: 1,300\n",
      "  Actual mean: 268423.76, std: 303966.49\n",
      "    LGBMRegressor                  -> RMSE:  178628.15, MAE:   78507.95, MAPE: 11910738956634046857216.00%, Norm_MAE:  29.25%\n",
      "    MinTrace_method-ols            -> RMSE:  178628.15, MAE:   78507.95, MAPE: 11910738956634048954368.00%, Norm_MAE:  29.25%\n",
      "\n",
      "================================================================================\n",
      "RECONCILIATION IMPACT (Comparing Base vs Reconciled)\n",
      "================================================================================\n",
      "                         MAE                             MAPE%                               RMSE                    \n",
      "Model          LGBMRegressor MinTrace_method-ols LGBMRegressor MinTrace_method-ols  LGBMRegressor MinTrace_method-ols\n",
      "Level                                                                                                                \n",
      "category        78507.951584        78507.951584  1.191074e+22        1.191074e+22  178628.153253       178628.153253\n",
      "store           12480.355731        12480.355731  6.567364e+20        6.567364e+20   18803.678290        18803.678290\n",
      "store_category    979.983667          979.983667  1.548639e+20        1.548639e+20    2769.423738         2769.423738\n",
      "\n",
      "================================================================================\n",
      "SAMPLE PREDICTIONS (First 10 bottom-level forecasts)\n",
      "================================================================================\n",
      "Empty DataFrame\n",
      "Columns: [unique_id, ds, y, LGBMRegressor, LGBMRegressor/MinTrace_method-ols]\n",
      "Index: []\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, mean_absolute_percentage_error\n",
    "import numpy as np\n",
    "\n",
    "from valuation.utils.metrics import compute_smape, compute_wape\n",
    "\n",
    "# 0 Print Hyperparameters\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(model_params)\n",
    "\n",
    "# 1. Get actuals at ALL hierarchy levels\n",
    "actuals_base = cv_df_base[['unique_id', 'ds', 'cutoff', 'y']].copy()\n",
    "actuals_base['store'] = actuals_base['unique_id'].apply(lambda s: s.split('_')[0])\n",
    "actuals_base['category'] = actuals_base['unique_id'].apply(lambda s: s.split('_')[1])\n",
    "actuals_base_for_agg = actuals_base.drop(columns=['unique_id'])\n",
    "\n",
    "# Aggregate actuals\n",
    "actuals_aggregated, _, _ = aggregate(df=actuals_base_for_agg, spec=spec)\n",
    "\n",
    "# 2. Merge forecasts with actuals\n",
    "cv_df_eval = cv_df_reconciled.merge(\n",
    "    actuals_aggregated[['unique_id', 'ds', 'y']], \n",
    "    on=['unique_id', 'ds'],\n",
    "    how='left'\n",
    ")\n",
    "\n",
    "# 3. Classify hierarchy levels properly\n",
    "def classify_level(uid):\n",
    "    if '_' in uid:\n",
    "        return 'bottom'  # store_category (e.g., \"100_beer\")\n",
    "    elif '/' in uid:\n",
    "        return 'store_category'  # aggregated store/category (e.g., \"100/beer\")\n",
    "    else:\n",
    "        # Check if it's a store (numeric) or category (text)\n",
    "        try:\n",
    "            int(uid)\n",
    "            return 'store'  # Just store (e.g., \"100\")\n",
    "        except:\n",
    "            return 'category'  # Just category (e.g., \"beer\")\n",
    "\n",
    "cv_df_eval['level'] = cv_df_eval['unique_id'].apply(classify_level)\n",
    "\n",
    "# 4. Get model columns\n",
    "model_cols = [col for col in cv_df_reconciled.columns \n",
    "              if col not in ['unique_id', 'ds', 'cutoff']]\n",
    "\n",
    "print(f\"Found model columns: {model_cols}\")\n",
    "print(f\"\\nDataset overview:\")\n",
    "print(f\"  Total forecasts: {len(cv_df_eval):,}\")\n",
    "print(f\"  Unique series: {cv_df_eval['unique_id'].nunique():,}\")\n",
    "print(f\"  Date range: {cv_df_eval['ds'].min()} to {cv_df_eval['ds'].max()}\")\n",
    "print(f\"\\nActual values summary:\")\n",
    "print(cv_df_eval['y'].describe())\n",
    "\n",
    "# 5. Overall Performance\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"OVERALL PERFORMANCE (All Hierarchy Levels)\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "performance_results = []\n",
    "for model_col in model_cols:\n",
    "    mask = cv_df_eval[[model_col, 'y']].notna().all(axis=1)\n",
    "    y_true = cv_df_eval.loc[mask, 'y']\n",
    "    y_pred = cv_df_eval.loc[mask, model_col]\n",
    "    \n",
    "    performance = {\n",
    "        'model': model_col.replace('LGBMRegressor/', ''),  # Shorter names\n",
    "        'MSE': mean_squared_error(y_true, y_pred),\n",
    "        'RMSE': np.sqrt(mean_squared_error(y_true, y_pred)),\n",
    "        'MAE': mean_absolute_error(y_true, y_pred),\n",
    "        'MAPE': mean_absolute_percentage_error(y_true, y_pred) * 100,  # As percentage\n",
    "        'SMAPE': compute_smape(y_true, y_pred),\n",
    "        'WAPE': compute_wape(y_true, y_pred),\n",
    "        'Mean_Actual': y_true.mean(),\n",
    "        'n_forecasts': len(y_true)}\n",
    "    \n",
    "    performance_results.append(performance)\n",
    "    run.log(performance)\n",
    "\n",
    "overall_perf = pd.DataFrame(performance_results).set_index('model')\n",
    "print(overall_perf.to_string())\n",
    "\n",
    "# 6. Performance by Hierarchy Level\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"PERFORMANCE BY HIERARCHY LEVEL\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "levels_order = ['bottom', 'store_category', 'store', 'category']\n",
    "level_results = []\n",
    "\n",
    "for level in levels_order:\n",
    "    level_data = cv_df_eval[cv_df_eval['level'] == level]\n",
    "    \n",
    "    if len(level_data) == 0:\n",
    "        continue\n",
    "        \n",
    "    print(f\"\\n{level.upper()} Level:\")\n",
    "    print(f\"  Unique series: {level_data['unique_id'].nunique():,}\")\n",
    "    print(f\"  Total forecasts: {len(level_data):,}\")\n",
    "    print(f\"  Actual mean: {level_data['y'].mean():.2f}, std: {level_data['y'].std():.2f}\")\n",
    "    \n",
    "    for model_col in model_cols:\n",
    "        mask = level_data[[model_col, 'y']].notna().all(axis=1)\n",
    "        y_true = level_data.loc[mask, 'y']\n",
    "        y_pred = level_data.loc[mask, model_col]\n",
    "        \n",
    "        if len(y_true) > 0:\n",
    "\n",
    "            rmse_val = np.sqrt(mean_squared_error(y_true, y_pred))\n",
    "            mae_val = mean_absolute_error(y_true, y_pred)\n",
    "            mape_val = mean_absolute_percentage_error(y_true, y_pred) * 100\n",
    "            smape_val = compute_smape(y_true, y_pred)\n",
    "            wape_val = compute_wape(y_true, y_pred)\n",
    "            \n",
    "            performance = {\n",
    "                \"Level\": level,\n",
    "                \"Model\": model_col.replace('LGBMRegressor/', ''),\n",
    "                'RMSE': rmse_val,\n",
    "                'MAE': mae_val,\n",
    "                'MAPE%': mape_val,\n",
    "                'Mean_Actual': y_true.mean(),\n",
    "                'n': len(y_true)\n",
    "            }\n",
    "            \n",
    "            level_results.append(performance)\n",
    "            \n",
    "            # Normalized error (MAE as % of mean)\n",
    "            normalized_mae = (mae_val / y_true.mean() * 100) if y_true.mean() > 0 else 0\n",
    "            \n",
    "            print(f\"    {model_col.replace('LGBMRegressor/', '')[:30]:30s} -> \"\n",
    "                  f\"RMSE: {rmse_val:>10.2f}, MAE: {mae_val:>10.2f}, \"\n",
    "                  f\"MAPE: {mape_val:>6.2f}%, Norm_MAE: {normalized_mae:>6.2f}%\")\n",
    "\n",
    "# 7. Comparison Table\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"RECONCILIATION IMPACT (Comparing Base vs Reconciled)\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "level_perf_df = pd.DataFrame(level_results)\n",
    "if len(level_perf_df) > 0:\n",
    "    comparison = level_perf_df.pivot_table(\n",
    "        index='Level',\n",
    "        columns='Model',\n",
    "        values=['RMSE', 'MAE', 'MAPE%']\n",
    "    )\n",
    "    print(comparison.to_string())\n",
    "\n",
    "# 8. Sample predictions vs actuals\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"SAMPLE PREDICTIONS (First 10 bottom-level forecasts)\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "sample = cv_df_eval[cv_df_eval['level'] == 'bottom'].head(10)[\n",
    "    ['unique_id', 'ds', 'y'] + model_cols\n",
    "].round(2)\n",
    "print(sample.to_string())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39f6656b",
   "metadata": {},
   "source": [
    "## Model Performance Diagnosis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "295fa077",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "PERFORMANCE DIAGNOSTICS\n",
      "================================================================================\n",
      "\n",
      "1. IMPUTATION ANALYSIS\n",
      "--------------------------------------------------------------------------------\n",
      "Series lengths after densification:\n",
      "  Min: 312, Max: 312\n",
      "  All equal: True\n",
      "\n",
      "‚ö†Ô∏è  Note: Imputation percentage not tracked.\n",
      "   If performance is poor, imputation may be the cause.\n",
      "\n",
      "2. TRAINING DATA QUALITY\n",
      "--------------------------------------------------------------------------------\n",
      "Training data shape: (811200, 3)\n",
      "Unique series: 2600\n",
      "Date range: 1990-01-03 00:00:00 to 1995-12-27 00:00:00\n",
      "\n",
      "Zero values: 25.0%\n",
      "Near-zero (<1): 25.0%\n",
      "\n",
      "Revenue distribution:\n",
      "count    811200.000000\n",
      "mean       1873.294832\n",
      "std        2428.830830\n",
      "min           0.000000\n",
      "25%           0.000000\n",
      "50%        1176.540000\n",
      "75%        2515.462500\n",
      "max      316838.770000\n",
      "Name: y, dtype: float64\n",
      "\n",
      "3. PREDICTION QUALITY ANALYSIS\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "LGBMRegressor:\n",
      "  Predictions range: [-9924.53, 1372205.15]\n",
      "  Actuals range: [0.00, 1903110.80]\n",
      "  Predictions mean: 8619.50 vs Actuals mean: 8254.11\n",
      "  ‚ö†Ô∏è  549 negative predictions (0.4%)\n",
      "  ‚ö†Ô∏è  457 extremely high predictions\n",
      "\n",
      "LGBMRegressor/MinTrace_method-ols:\n",
      "  Predictions range: [-9924.53, 1372205.15]\n",
      "  Actuals range: [0.00, 1903110.80]\n",
      "  Predictions mean: 8619.50 vs Actuals mean: 8254.11\n",
      "  ‚ö†Ô∏è  549 negative predictions (0.4%)\n",
      "  ‚ö†Ô∏è  457 extremely high predictions\n",
      "\n",
      "4. RESIDUAL ANALYSIS\n",
      "--------------------------------------------------------------------------------\n",
      "Analyzing LGBMRegressor:\n",
      "  Mean residual: -365.38\n",
      "  Median residual: -86.70\n",
      "  Residual std: 18646.99\n",
      "  Mean absolute error: 2213.17\n",
      "\n",
      "5. DIFFERENCING IMPACT\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "6. DATA LEAKAGE CHECK\n",
      "--------------------------------------------------------------------------------\n",
      "CV windows per series: 3    2600\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Cutoff dates: [Timestamp('1994-12-28 00:00:00'), Timestamp('1995-03-29 00:00:00'), Timestamp('1995-06-28 00:00:00')]\n",
      "\n",
      "7. WORST PERFORMING SERIES\n",
      "--------------------------------------------------------------------------------\n",
      "Top 10 worst series (by MAE):\n",
      "  cereals                        MAE:  622136.77, Actual mean:  442916.22, Pred mean:  731444.99\n",
      "  frozen                         MAE:  159756.34, Actual mean:  898078.91, Pred mean:  933017.71\n",
      "  cheeses-                       MAE:  143973.23, Actual mean:  883715.35, Pred mean:  834328.56\n",
      "  beer                           MAE:  127789.13, Actual mean:  492593.46, Pred mean:  518721.96\n",
      "  canned                         MAE:  116652.36, Actual mean:  512920.02, Pred mean:  545780.39\n",
      "  laundry                        MAE:  108432.61, Actual mean:  496868.90, Pred mean:  496798.25\n",
      "  shampoos                       MAE:   85960.87, Actual mean:   19833.19, Pred mean:  100411.77\n",
      "  cookies                        MAE:   84661.15, Actual mean:  489123.35, Pred mean:  494375.75\n",
      "  bathroom                       MAE:   83283.67, Actual mean:  281472.34, Pred mean:  306870.20\n",
      "  snack                          MAE:   75258.72, Actual mean:  258854.44, Pred mean:  192726.74\n",
      "\n",
      "================================================================================\n",
      "RECOMMENDATIONS\n",
      "================================================================================\n",
      "\n",
      "Based on diagnostics above, try these fixes:\n",
      "\n",
      "1. REMOVE DIFFERENCING if series are short or heavily imputed:\n",
      "   TARGET_TRANSFORMS = []  # Remove Differences([1])\n",
      "\n",
      "2. REDUCE LAGS if many series are short:\n",
      "   LAGS = [1, 2, 4, 8, 13]  # Remove 26, 52\n",
      "\n",
      "3. FILTER OUT heavily imputed series (>30% imputed)\n",
      "\n",
      "4. CHECK if forward/backward fill is creating unrealistic patterns\n",
      "\n",
      "5. INCREASE min_child_samples for more regularization:\n",
      "   min_child_samples=50 or 100\n",
      "\n",
      "6. ADD more regularization:\n",
      "   reg_alpha=1.0, reg_lambda=1.0\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_165673/325933447.py:129: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  series_mae = cv_df_eval.groupby('unique_id').apply(\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(\"=\"*80)\n",
    "print(\"PERFORMANCE DIAGNOSTICS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# 1. Check imputation impact\n",
    "print(\"\\n1. IMPUTATION ANALYSIS\")\n",
    "print(\"-\"*80)\n",
    "\n",
    "# Check what percentage of data was originally missing\n",
    "# This assumes train_df is your final densified/imputed dataset\n",
    "if 'train_df' in locals():\n",
    "    # Check series lengths - all should be equal after densification\n",
    "    series_lengths = train_df.groupby('unique_id').size()\n",
    "    print(f\"Series lengths after densification:\")\n",
    "    print(f\"  Min: {series_lengths.min()}, Max: {series_lengths.max()}\")\n",
    "    print(f\"  All equal: {len(series_lengths.unique()) == 1}\")\n",
    "    \n",
    "    # If you tracked NaNs before imputation, report it\n",
    "    # Otherwise, skip this section\n",
    "    print(\"\\n‚ö†Ô∏è  Note: Imputation percentage not tracked.\")\n",
    "    print(\"   If performance is poor, imputation may be the cause.\")\n",
    "\n",
    "# 2. Check training data quality\n",
    "print(\"\\n2. TRAINING DATA QUALITY\")\n",
    "print(\"-\"*80)\n",
    "\n",
    "if 'train_df' in locals():\n",
    "    print(f\"Training data shape: {train_df.shape}\")\n",
    "    print(f\"Unique series: {train_df['unique_id'].nunique()}\")\n",
    "    print(f\"Date range: {train_df['ds'].min()} to {train_df['ds'].max()}\")\n",
    "    \n",
    "    # Check for zero/near-zero values\n",
    "    zero_pct = (train_df['y'] == 0).sum() / len(train_df) * 100\n",
    "    near_zero_pct = (train_df['y'] < 1).sum() / len(train_df) * 100\n",
    "    print(f\"\\nZero values: {zero_pct:.1f}%\")\n",
    "    print(f\"Near-zero (<1): {near_zero_pct:.1f}%\")\n",
    "    \n",
    "    # Revenue distribution\n",
    "    print(f\"\\nRevenue distribution:\")\n",
    "    print(train_df['y'].describe())\n",
    "    \n",
    "    # Check for negative values\n",
    "    if (train_df['y'] < 0).any():\n",
    "        print(f\"‚ö†Ô∏è  WARNING: {(train_df['y'] < 0).sum()} negative values found!\")\n",
    "\n",
    "# 3. Check predictions quality\n",
    "print(\"\\n3. PREDICTION QUALITY ANALYSIS\")\n",
    "print(\"-\"*80)\n",
    "\n",
    "if 'cv_df_eval' in locals() and 'model_cols' in locals():\n",
    "    # Check for extreme predictions\n",
    "    for model_col in model_cols:\n",
    "        preds = cv_df_eval[model_col].dropna()\n",
    "        actuals = cv_df_eval['y'].dropna()\n",
    "        \n",
    "        print(f\"\\n{model_col}:\")\n",
    "        print(f\"  Predictions range: [{preds.min():.2f}, {preds.max():.2f}]\")\n",
    "        print(f\"  Actuals range: [{actuals.min():.2f}, {actuals.max():.2f}]\")\n",
    "        print(f\"  Predictions mean: {preds.mean():.2f} vs Actuals mean: {actuals.mean():.2f}\")\n",
    "        \n",
    "        # Check for negative predictions\n",
    "        neg_preds = (preds < 0).sum()\n",
    "        if neg_preds > 0:\n",
    "            print(f\"  ‚ö†Ô∏è  {neg_preds} negative predictions ({neg_preds/len(preds)*100:.1f}%)\")\n",
    "        \n",
    "        # Check for extreme predictions\n",
    "        extreme_high = (preds > actuals.quantile(0.99) * 2).sum()\n",
    "        if extreme_high > 0:\n",
    "            print(f\"  ‚ö†Ô∏è  {extreme_high} extremely high predictions\")\n",
    "\n",
    "# 4. Residual analysis\n",
    "print(\"\\n4. RESIDUAL ANALYSIS\")\n",
    "print(\"-\"*80)\n",
    "\n",
    "if 'cv_df_eval' in locals() and len(model_cols) > 0:\n",
    "    model_col = model_cols[0]  # Analyze first model\n",
    "    \n",
    "    mask = cv_df_eval[[model_col, 'y']].notna().all(axis=1)\n",
    "    actuals = cv_df_eval.loc[mask, 'y']\n",
    "    preds = cv_df_eval.loc[mask, model_col]\n",
    "    residuals = actuals - preds\n",
    "    \n",
    "    print(f\"Analyzing {model_col}:\")\n",
    "    print(f\"  Mean residual: {residuals.mean():.2f}\")\n",
    "    print(f\"  Median residual: {residuals.median():.2f}\")\n",
    "    print(f\"  Residual std: {residuals.std():.2f}\")\n",
    "    print(f\"  Mean absolute error: {np.abs(residuals).mean():.2f}\")\n",
    "    \n",
    "    # Check for systematic bias\n",
    "    if abs(residuals.mean()) > actuals.std() * 0.1:\n",
    "        print(f\"  ‚ö†Ô∏è  WARNING: Systematic bias detected!\")\n",
    "        if residuals.mean() > 0:\n",
    "            print(f\"     Model is UNDER-predicting on average\")\n",
    "        else:\n",
    "            print(f\"     Model is OVER-predicting on average\")\n",
    "\n",
    "# 5. Check differences transformation\n",
    "print(\"\\n5. DIFFERENCING IMPACT\")\n",
    "print(\"-\"*80)\n",
    "\n",
    "if 'TARGET_TRANSFORMS' in locals() and len(mlforecast_params.target_transforms) > 0:\n",
    "    print(f\"Target transforms applied: {mlforecast_params.target_transforms}\")\n",
    "    print(\"‚ö†Ô∏è  Differencing can cause issues if:\")\n",
    "    print(\"   - Series are short\")\n",
    "    print(\"   - Series have many imputed values\")\n",
    "    print(\"   - Series are already stationary\")\n",
    "    print(\"\\nüí° RECOMMENDATION: Try removing Differences([1]) and see if performance improves\")\n",
    "\n",
    "# 6. Check for data leakage\n",
    "print(\"\\n6. DATA LEAKAGE CHECK\")\n",
    "print(\"-\"*80)\n",
    "\n",
    "if 'cv_df_base' in locals():\n",
    "    # Check if CV is working correctly\n",
    "    cv_windows = cv_df_base.groupby(['unique_id', 'cutoff']).size()\n",
    "    print(f\"CV windows per series: {cv_windows.groupby(level=0).size().value_counts()}\")\n",
    "    \n",
    "    # Check cutoff dates\n",
    "    print(f\"\\nCutoff dates: {sorted(cv_df_base['cutoff'].unique())}\")\n",
    "\n",
    "# 7. Specific problematic series\n",
    "print(\"\\n7. WORST PERFORMING SERIES\")\n",
    "print(\"-\"*80)\n",
    "\n",
    "if 'cv_df_eval' in locals() and 'model_cols' in locals():\n",
    "    model_col = model_cols[0]\n",
    "    \n",
    "    # Calculate MAE per series\n",
    "    series_mae = cv_df_eval.groupby('unique_id').apply(\n",
    "        lambda x: mean_absolute_error(x['y'].dropna(), x[model_col].dropna()) \n",
    "        if len(x['y'].dropna()) > 0 else np.nan\n",
    "    ).sort_values(ascending=False)\n",
    "    \n",
    "    print(\"Top 10 worst series (by MAE):\")\n",
    "    for uid, mae in series_mae.head(10).items():\n",
    "        series_data = cv_df_eval[cv_df_eval['unique_id'] == uid]\n",
    "        actual_mean = series_data['y'].mean()\n",
    "        pred_mean = series_data[model_col].mean()\n",
    "        print(f\"  {uid:30s} MAE: {mae:>10.2f}, Actual mean: {actual_mean:>10.2f}, Pred mean: {pred_mean:>10.2f}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"RECOMMENDATIONS\")\n",
    "print(\"=\"*80)\n",
    "print(\"\"\"\n",
    "Based on diagnostics above, try these fixes:\n",
    "\n",
    "1. REMOVE DIFFERENCING if series are short or heavily imputed:\n",
    "   TARGET_TRANSFORMS = []  # Remove Differences([1])\n",
    "\n",
    "2. REDUCE LAGS if many series are short:\n",
    "   LAGS = [1, 2, 4, 8, 13]  # Remove 26, 52\n",
    "\n",
    "3. FILTER OUT heavily imputed series (>30% imputed)\n",
    "\n",
    "4. CHECK if forward/backward fill is creating unrealistic patterns\n",
    "\n",
    "5. INCREASE min_child_samples for more regularization:\n",
    "   min_child_samples=50 or 100\n",
    "\n",
    "6. ADD more regularization:\n",
    "   reg_alpha=1.0, reg_lambda=1.0\n",
    "\"\"\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "valuation",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
