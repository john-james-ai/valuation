{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "43cb608e",
   "metadata": {},
   "source": [
    "# LightGBM Model Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "623f8049",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from lightgbm import LGBMRegressor # The ML model\n",
    "\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "import wandb\n",
    "from sklearn.pipeline import FunctionTransformer\n",
    "\n",
    "\n",
    "from hierarchicalforecast.core import HierarchicalReconciliation\n",
    "from hierarchicalforecast.methods import MinTrace, BottomUp\n",
    "from hierarchicalforecast.utils import aggregate\n",
    "from hierarchicalforecast.core import HierarchicalReconciliation\n",
    "from mlforecast import MLForecast\n",
    "from mlforecast.target_transforms import GlobalSklearnTransformer\n",
    "\n",
    "from valuation.infra.store.dataset import DatasetStore\n",
    "from valuation.asset.identity.dataset import DatasetID\n",
    "from valuation.core.stage import DatasetStage\n",
    "from valuation.asset.identity.model import ModelPassport\n",
    "from valuation.asset.model.mlforecast import MLForecastModel\n",
    "from valuation.infra.store.model import ModelStore\n",
    "from valuation.flow.modeling.model_selection.light_gbm import LightGBMHP\n",
    "from valuation.flow.modeling.model_selection.cv import CrossValidationHP\n",
    "from valuation.flow.modeling.model_selection.mlforecast import MLForecastHP\n",
    "from valuation.flow.modeling.model_selection.base import ModelParams\n",
    "\n",
    "# Suppress the specific warning\n",
    "warnings.filterwarnings('ignore', message='.*lag.*')\n",
    "warnings.filterwarnings('ignore', message='.*UnsupportedFieldAttributeWarning.*')\n",
    "wandb.login()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bc1866f",
   "metadata": {},
   "source": [
    "## Model Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "74bcf1c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_CORES = 24              # Total CPU cores available\n",
    "# Reproducibility \n",
    "RANDOM_STATE = 42           # Fixed random seed\n",
    "\n",
    "MODELS = [LGBMRegressor(**LightGBMHP(tweedie_variance_power=1.2).as_dict()),\n",
    "          LGBMRegressor(**LightGBMHP(tweedie_variance_power=1.3).as_dict()),\n",
    "          LGBMRegressor(**LightGBMHP(tweedie_variance_power=1.4).as_dict()),\n",
    "          LGBMRegressor(**LightGBMHP(tweedie_variance_power=1.5).as_dict()),\n",
    "]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35da959f",
   "metadata": {},
   "source": [
    "## Training Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d9ce279e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-10-24 03:52:19.772\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mvaluation.asset.dataset.base\u001b[0m:\u001b[36mload\u001b[0m:\u001b[36m338\u001b[0m - \u001b[34m\u001b[1mDataset Dataset train_val of the model stage created on 2025-10-24 at 01:30 loaded.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "store = DatasetStore()\n",
    "dataset_id = DatasetID(name=\"train_val\", stage=DatasetStage.MODEL)\n",
    "passport = store.get_passport(dataset_id=dataset_id)\n",
    "ds = store.get(passport=passport)\n",
    "train_df = ds.data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e206bd5",
   "metadata": {},
   "source": [
    "## Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b3e68cb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "mf = MLForecast(models=MODELS,**MLForecastHP().as_dict())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88113e58",
   "metadata": {},
   "source": [
    "## Blocked Cross-Validation\n",
    "This generates the unreconciled forecasts for each fold. We must add fitted=True to get the in-sample forecasts for the reconciler."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "be524319",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MLForecast(models=[LGBMRegressor, LGBMRegressor2, LGBMRegressor3, LGBMRegressor4], freq=W-WED, lag_features=['lag1', 'lag2', 'lag4', 'lag13', 'lag52', 'lag43', 'rolling_mean_lag1_window_size4', 'rolling_mean_lag1_window_size13', 'rolling_mean_lag52_window_size5'], date_features=['week', 'month', 'dayofyear'], num_threads=22)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv_df_base = mf.cross_validation(\n",
    "    df=train_df, **CrossValidationHP().as_dict())\n",
    "mf.fit(df=train_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e858377",
   "metadata": {},
   "source": [
    "## Create Summing Matrix and Tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b9919aa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Start with the core data (unique_id, ds, y)\n",
    "hierarchy_df = train_df[['unique_id', 'ds', 'y']].drop_duplicates() \n",
    "\n",
    "# 2. Create the grouping columns\n",
    "hierarchy_df['store'] = hierarchy_df['unique_id'].apply(lambda s: s.split('_')[0])\n",
    "hierarchy_df['category'] = hierarchy_df['unique_id'].apply(lambda s: s.split('_')[1])\n",
    "\n",
    "# 3. Drop the 'unique_id' column from the input DF before aggregation\n",
    "#    The aggregate function knows to use the combination of columns in 'spec'\n",
    "#    to uniquely identify the time series levels.\n",
    "hierarchy_df_clean = hierarchy_df.drop(columns=['unique_id']) # üëà ADD THIS LINE\n",
    "\n",
    "spec = [['store'], ['category'], ['store', 'category']]\n",
    "\n",
    "# Pass the cleaned DataFrame to the aggregate function\n",
    "_, S_df, tags = aggregate(df=hierarchy_df_clean, spec=spec)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a24b160d",
   "metadata": {},
   "source": [
    "## Aggregate Forecasts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "16c822b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Forecasts aggregated successfully across all hierarchy levels.\n",
      "Base forecasts shape: (202800, 6)\n",
      "Aggregated forecasts shape: (141492, 3)\n",
      "Unique IDs in aggregated forecasts: 2721\n"
     ]
    }
   ],
   "source": [
    "# Clean and Prepare Y_hat_df_base\n",
    "Y_hat_df_base = cv_df_base.drop(columns=['cutoff', 'y'], errors='ignore')\n",
    "\n",
    "# 1. Add the hierarchy columns to the base forecasts\n",
    "Y_hat_df_base_clean = Y_hat_df_base.copy()\n",
    "Y_hat_df_base_clean['store'] = Y_hat_df_base_clean['unique_id'].apply(lambda s: s.split('_')[0])\n",
    "Y_hat_df_base_clean['category'] = Y_hat_df_base_clean['unique_id'].apply(lambda s: s.split('_')[1])\n",
    "\n",
    "# 2. Identify the forecast column(s) - typically 'LGBMRegressor' or similar model name\n",
    "forecast_col = 'LGBMRegressor'  # Adjust if your column has a different name\n",
    "\n",
    "# 3. Rename forecast column to 'y' temporarily for aggregation\n",
    "Y_hat_df_base_for_agg = Y_hat_df_base_clean.copy()\n",
    "Y_hat_df_base_for_agg = Y_hat_df_base_for_agg.rename(columns={forecast_col: 'y'})\n",
    "Y_hat_df_base_for_agg = Y_hat_df_base_for_agg.drop(columns=['unique_id'])\n",
    "\n",
    "# 4. Aggregate to create forecasts at all hierarchy levels\n",
    "Y_hat_aggregated, _, _ = aggregate(df=Y_hat_df_base_for_agg, spec=spec)\n",
    "\n",
    "# 5. Rename back to original forecast column name\n",
    "Y_hat_aggregated = Y_hat_aggregated.rename(columns={'y': forecast_col})\n",
    "\n",
    "print(\"Forecasts aggregated successfully across all hierarchy levels.\")\n",
    "print(f\"Base forecasts shape: {Y_hat_df_base.shape}\")\n",
    "print(f\"Aggregated forecasts shape: {Y_hat_aggregated.shape}\")\n",
    "print(f\"Unique IDs in aggregated forecasts: {Y_hat_aggregated['unique_id'].nunique()}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75bc6e33",
   "metadata": {},
   "source": [
    "## Reconciler for CV Forecasts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0cfff44e",
   "metadata": {},
   "outputs": [],
   "source": [
    "reconcilers = [MinTrace(method='ols')]\n",
    "hrec = HierarchicalReconciliation(reconcilers=reconcilers)\n",
    "\n",
    "# Prepare aggregated actuals\n",
    "Y_df_base = cv_df_base[['unique_id', 'ds', 'y']].copy()\n",
    "Y_df_base['store'] = Y_df_base['unique_id'].apply(lambda s: s.split('_')[0])\n",
    "Y_df_base['category'] = Y_df_base['unique_id'].apply(lambda s: s.split('_')[1])\n",
    "Y_df_base_for_agg = Y_df_base.drop(columns=['unique_id'])\n",
    "Y_df_actuals, _, _ = aggregate(df=Y_df_base_for_agg, spec=spec)\n",
    "\n",
    "# Reconcile (this adjusts the aggregated forecasts for coherence)\n",
    "cv_df_reconciled = hrec.reconcile(\n",
    "    Y_hat_df=Y_hat_aggregated,  # Now has all hierarchy levels\n",
    "    Y_df=Y_df_actuals,\n",
    "    S_df=S_df,\n",
    "    tags=tags\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1f42215",
   "metadata": {},
   "source": [
    "## Evaluate CV Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3ad9ba1c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.22.2"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/john/projects/valuation/wandb/run-20251024_040134-ru90ysjb</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/aistudio/valuation/runs/ru90ysjb' target=\"_blank\">northern-voice-10</a></strong> to <a href='https://wandb.ai/aistudio/valuation' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/aistudio/valuation' target=\"_blank\">https://wandb.ai/aistudio/valuation</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/aistudio/valuation/runs/ru90ysjb' target=\"_blank\">https://wandb.ai/aistudio/valuation/runs/ru90ysjb</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found model columns: ['LGBMRegressor', 'LGBMRegressor/MinTrace_method-ols']\n",
      "\n",
      "Dataset overview:\n",
      "  Total forecasts: 141,492\n",
      "  Unique series: 2,721\n",
      "  Date range: 1995-01-04 00:00:00 to 1995-12-27 00:00:00\n",
      "\n",
      "Actual values summary:\n",
      "count         141492.0\n",
      "mean       30142.27635\n",
      "std      190899.049374\n",
      "min                0.0\n",
      "25%          1334.1525\n",
      "50%            5400.57\n",
      "75%           12730.56\n",
      "max        14800224.78\n",
      "Name: y, dtype: double[pyarrow]\n",
      "\n",
      "================================================================================\n",
      "OVERALL PERFORMANCE (All Hierarchy Levels)\n",
      "================================================================================\n",
      "                              MSE          RMSE          MAE          MAPE      SMAPE       WAPE  Mean_Actual  n_forecasts\n",
      "model                                                                                                                     \n",
      "LGBMRegressor        4.515441e+09  67197.032441  7446.068713  8.666328e+20  59.512188  24.703074  30142.27635       141492\n",
      "MinTrace_method-ols  4.515441e+09  67197.032441  7446.068713  8.666328e+20  59.512188  24.703074  30142.27635       141492\n",
      "\n",
      "================================================================================\n",
      "PERFORMANCE BY HIERARCHY LEVEL\n",
      "================================================================================\n",
      "\n",
      "STORE_CATEGORY Level:\n",
      "  Unique series: 2,600\n",
      "  Total forecasts: 135,200\n",
      "  Actual mean: 10515.02, std: 19503.08\n",
      "    LGBMRegressor                  -> RMSE:    9840.24, MAE:    3381.12, MAPE: 449378381009368186880.00%, Norm_MAE:  32.16%\n",
      "    MinTrace_method-ols            -> RMSE:    9840.24, MAE:    3381.12, MAPE: 449378381009368317952.00%, Norm_MAE:  32.16%\n",
      "\n",
      "STORE Level:\n",
      "  Unique series: 93\n",
      "  Total forecasts: 4,836\n",
      "  Actual mean: 293968.22, std: 185211.23\n",
      "    LGBMRegressor                  -> RMSE:   65814.55, MAE:   43186.44, MAPE: 2761284964844348375040.00%, Norm_MAE:  14.69%\n",
      "    MinTrace_method-ols            -> RMSE:   65814.55, MAE:   43186.44, MAPE: 2761284964844348375040.00%, Norm_MAE:  14.69%\n",
      "\n",
      "CATEGORY Level:\n",
      "  Unique series: 28\n",
      "  Total forecasts: 1,456\n",
      "  Actual mean: 976394.45, std: 1493770.71\n",
      "    LGBMRegressor                  -> RMSE:  644535.32, MAE:  266196.49, MAPE: 33318734724408608292864.00%, Norm_MAE:  27.26%\n",
      "    MinTrace_method-ols            -> RMSE:  644535.32, MAE:  266196.49, MAPE: 33318734724408608292864.00%, Norm_MAE:  27.26%\n",
      "\n",
      "================================================================================\n",
      "RECONCILIATION IMPACT (Comparing Base vs Reconciled)\n",
      "================================================================================\n",
      "                          MAE                             MAPE%                               RMSE                    \n",
      "Model           LGBMRegressor MinTrace_method-ols LGBMRegressor MinTrace_method-ols  LGBMRegressor MinTrace_method-ols\n",
      "Level                                                                                                                 \n",
      "category        266196.487436       266196.487436  3.331873e+22        3.331873e+22  644535.322373       644535.322373\n",
      "store            43186.442566        43186.442566  2.761285e+21        2.761285e+21   65814.546961        65814.546961\n",
      "store_category    3381.120063         3381.120063  4.493784e+20        4.493784e+20    9840.242205         9840.242205\n",
      "\n",
      "================================================================================\n",
      "SAMPLE PREDICTIONS (First 10 bottom-level forecasts)\n",
      "================================================================================\n",
      "Empty DataFrame\n",
      "Columns: [unique_id, ds, y, LGBMRegressor, LGBMRegressor/MinTrace_method-ols]\n",
      "Index: []\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, mean_absolute_percentage_error\n",
    "import numpy as np\n",
    "\n",
    "from valuation.utils.metrics import compute_smape, compute_wape\n",
    "\n",
    "run = wandb.init(project=\"valuation\", job_type=\"modeling\")\n",
    "\n",
    "# 1. Get actuals at ALL hierarchy levels\n",
    "actuals_base = cv_df_base[['unique_id', 'ds', 'cutoff', 'y']].copy()\n",
    "actuals_base['store'] = actuals_base['unique_id'].apply(lambda s: s.split('_')[0])\n",
    "actuals_base['category'] = actuals_base['unique_id'].apply(lambda s: s.split('_')[1])\n",
    "actuals_base_for_agg = actuals_base.drop(columns=['unique_id'])\n",
    "\n",
    "# Aggregate actuals\n",
    "actuals_aggregated, _, _ = aggregate(df=actuals_base_for_agg, spec=spec)\n",
    "\n",
    "# 2. Merge forecasts with actuals\n",
    "cv_df_eval = cv_df_reconciled.merge(\n",
    "    actuals_aggregated[['unique_id', 'ds', 'y']], \n",
    "    on=['unique_id', 'ds'],\n",
    "    how='left'\n",
    ")\n",
    "\n",
    "# 3. Classify hierarchy levels properly\n",
    "def classify_level(uid):\n",
    "    if '_' in uid:\n",
    "        return 'bottom'  # store_category (e.g., \"100_beer\")\n",
    "    elif '/' in uid:\n",
    "        return 'store_category'  # aggregated store/category (e.g., \"100/beer\")\n",
    "    else:\n",
    "        # Check if it's a store (numeric) or category (text)\n",
    "        try:\n",
    "            int(uid)\n",
    "            return 'store'  # Just store (e.g., \"100\")\n",
    "        except:\n",
    "            return 'category'  # Just category (e.g., \"beer\")\n",
    "\n",
    "cv_df_eval['level'] = cv_df_eval['unique_id'].apply(classify_level)\n",
    "\n",
    "# 4. Get model columns\n",
    "model_cols = [col for col in cv_df_reconciled.columns \n",
    "              if col not in ['unique_id', 'ds', 'cutoff']]\n",
    "\n",
    "print(f\"Found model columns: {model_cols}\")\n",
    "print(f\"\\nDataset overview:\")\n",
    "print(f\"  Total forecasts: {len(cv_df_eval):,}\")\n",
    "print(f\"  Unique series: {cv_df_eval['unique_id'].nunique():,}\")\n",
    "print(f\"  Date range: {cv_df_eval['ds'].min()} to {cv_df_eval['ds'].max()}\")\n",
    "print(f\"\\nActual values summary:\")\n",
    "print(cv_df_eval['y'].describe())\n",
    "\n",
    "# 5. Overall Performance\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"OVERALL PERFORMANCE (All Hierarchy Levels)\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "performance_results = []\n",
    "for model_col in model_cols:\n",
    "    mask = cv_df_eval[[model_col, 'y']].notna().all(axis=1)\n",
    "    y_true = cv_df_eval.loc[mask, 'y']\n",
    "    y_pred = cv_df_eval.loc[mask, model_col]\n",
    "    \n",
    "    performance = {\n",
    "        'model': model_col.replace('LGBMRegressor/', ''),  # Shorter names\n",
    "        'MSE': mean_squared_error(y_true, y_pred),\n",
    "        'RMSE': np.sqrt(mean_squared_error(y_true, y_pred)),\n",
    "        'MAE': mean_absolute_error(y_true, y_pred),\n",
    "        'MAPE': mean_absolute_percentage_error(y_true, y_pred) * 100,  # As percentage\n",
    "        'SMAPE': compute_smape(y_true, y_pred),\n",
    "        'WAPE': compute_wape(y_true, y_pred),\n",
    "        'Mean_Actual': y_true.mean(),\n",
    "        'n_forecasts': len(y_true)}\n",
    "    \n",
    "    performance_results.append(performance)\n",
    "    run.log(performance)\n",
    "\n",
    "overall_perf = pd.DataFrame(performance_results).set_index('model')\n",
    "print(overall_perf.to_string())\n",
    "\n",
    "# 6. Performance by Hierarchy Level\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"PERFORMANCE BY HIERARCHY LEVEL\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "levels_order = ['bottom', 'store_category', 'store', 'category']\n",
    "level_results = []\n",
    "\n",
    "for level in levels_order:\n",
    "    level_data = cv_df_eval[cv_df_eval['level'] == level]\n",
    "    \n",
    "    if len(level_data) == 0:\n",
    "        continue\n",
    "        \n",
    "    print(f\"\\n{level.upper()} Level:\")\n",
    "    print(f\"  Unique series: {level_data['unique_id'].nunique():,}\")\n",
    "    print(f\"  Total forecasts: {len(level_data):,}\")\n",
    "    print(f\"  Actual mean: {level_data['y'].mean():.2f}, std: {level_data['y'].std():.2f}\")\n",
    "    \n",
    "    for model_col in model_cols:\n",
    "        mask = level_data[[model_col, 'y']].notna().all(axis=1)\n",
    "        y_true = level_data.loc[mask, 'y']\n",
    "        y_pred = level_data.loc[mask, model_col]\n",
    "        \n",
    "        if len(y_true) > 0:\n",
    "\n",
    "            rmse_val = np.sqrt(mean_squared_error(y_true, y_pred))\n",
    "            mae_val = mean_absolute_error(y_true, y_pred)\n",
    "            mape_val = mean_absolute_percentage_error(y_true, y_pred) * 100\n",
    "            smape_val = compute_smape(y_true, y_pred)\n",
    "            wape_val = compute_wape(y_true, y_pred)\n",
    "            \n",
    "            performance = {\n",
    "                \"Level\": level,\n",
    "                \"Model\": model_col.replace('LGBMRegressor/', ''),\n",
    "                'RMSE': rmse_val,\n",
    "                'MAE': mae_val,\n",
    "                'MAPE%': mape_val,\n",
    "                'Mean_Actual': y_true.mean(),\n",
    "                'n': len(y_true)\n",
    "            }\n",
    "            \n",
    "            level_results.append(performance)\n",
    "            \n",
    "            # Normalized error (MAE as % of mean)\n",
    "            normalized_mae = (mae_val / y_true.mean() * 100) if y_true.mean() > 0 else 0\n",
    "            \n",
    "            print(f\"    {model_col.replace('LGBMRegressor/', '')[:30]:30s} -> \"\n",
    "                  f\"RMSE: {rmse_val:>10.2f}, MAE: {mae_val:>10.2f}, \"\n",
    "                  f\"MAPE: {mape_val:>6.2f}%, Norm_MAE: {normalized_mae:>6.2f}%\")\n",
    "\n",
    "# 7. Comparison Table\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"RECONCILIATION IMPACT (Comparing Base vs Reconciled)\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "level_perf_df = pd.DataFrame(level_results)\n",
    "if len(level_perf_df) > 0:\n",
    "    comparison = level_perf_df.pivot_table(\n",
    "        index='Level',\n",
    "        columns='Model',\n",
    "        values=['RMSE', 'MAE', 'MAPE%']\n",
    "    )\n",
    "    print(comparison.to_string())\n",
    "\n",
    "# 8. Sample predictions vs actuals\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"SAMPLE PREDICTIONS (First 10 bottom-level forecasts)\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "sample = cv_df_eval[cv_df_eval['level'] == 'bottom'].head(10)[\n",
    "    ['unique_id', 'ds', 'y'] + model_cols\n",
    "].round(2)\n",
    "print(sample.to_string())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39f6656b",
   "metadata": {},
   "source": [
    "## Model Performance Diagnosis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "295fa077",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "PERFORMANCE DIAGNOSTICS\n",
      "================================================================================\n",
      "\n",
      "1. IMPUTATION ANALYSIS\n",
      "--------------------------------------------------------------------------------\n",
      "Series lengths after densification:\n",
      "  Min: 313, Max: 313\n",
      "  All equal: True\n",
      "\n",
      "‚ö†Ô∏è  Note: Imputation percentage not tracked.\n",
      "   If performance is poor, imputation may be the cause.\n",
      "\n",
      "2. TRAINING DATA QUALITY\n",
      "--------------------------------------------------------------------------------\n",
      "Training data shape: (813800, 3)\n",
      "Unique series: 2600\n",
      "Date range: 1990-01-03 00:00:00 to 1995-12-27 00:00:00\n",
      "\n",
      "Zero values: 21.5%\n",
      "Near-zero (<1): 21.5%\n",
      "\n",
      "Revenue distribution:\n",
      "count        813800.0\n",
      "mean      6942.470871\n",
      "std      10024.185717\n",
      "min               0.0\n",
      "25%          836.4825\n",
      "50%          3891.705\n",
      "75%         8409.0675\n",
      "max         950516.31\n",
      "Name: y, dtype: double[pyarrow]\n",
      "\n",
      "3. PREDICTION QUALITY ANALYSIS\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "LGBMRegressor:\n",
      "  Predictions range: [-14627.85, 10772970.60]\n",
      "  Actuals range: [0.00, 14800224.78]\n",
      "  Predictions mean: 30277.86 vs Actuals mean: 30142.28\n",
      "  ‚ö†Ô∏è  1228 negative predictions (0.9%)\n",
      "  ‚ö†Ô∏è  387 extremely high predictions\n",
      "\n",
      "LGBMRegressor/MinTrace_method-ols:\n",
      "  Predictions range: [-14627.85, 10772970.60]\n",
      "  Actuals range: [0.00, 14800224.78]\n",
      "  Predictions mean: 30277.86 vs Actuals mean: 30142.28\n",
      "  ‚ö†Ô∏è  1228 negative predictions (0.9%)\n",
      "  ‚ö†Ô∏è  387 extremely high predictions\n",
      "\n",
      "4. RESIDUAL ANALYSIS\n",
      "--------------------------------------------------------------------------------\n",
      "Analyzing LGBMRegressor:\n",
      "  Mean residual: -135.59\n",
      "  Median residual: -230.26\n",
      "  Residual std: 67197.13\n",
      "  Mean absolute error: 7446.07\n",
      "\n",
      "5. DIFFERENCING IMPACT\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "6. DATA LEAKAGE CHECK\n",
      "--------------------------------------------------------------------------------\n",
      "CV windows per series: 3    2600\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Cutoff dates: [Timestamp('1994-12-28 00:00:00'), Timestamp('1995-03-29 00:00:00'), Timestamp('1995-06-28 00:00:00')]\n",
      "\n",
      "7. WORST PERFORMING SERIES\n",
      "--------------------------------------------------------------------------------\n",
      "Top 10 worst series (by MAE):\n",
      "  cereals                        MAE: 1734559.14, Actual mean: 1328748.66, Pred mean: 2432225.94\n",
      "  soft drinks                    MAE: 1616327.43, Actual mean: 6919357.76, Pred mean: 5890169.12\n",
      "  frozen entrees                 MAE:  429819.78, Actual mean: 1595798.91, Pred mean: 1724081.10\n",
      "  beer                           MAE:  402450.99, Actual mean: 1477780.37, Pred mean: 1572780.37\n",
      "  cheeses-                       MAE:  354688.78, Actual mean: 2651146.04, Pred mean: 2537322.67\n",
      "  laundry detergents             MAE:  328824.41, Actual mean: 1490606.70, Pred mean: 1516475.11\n",
      "  canned soup                    MAE:  310828.98, Actual mean:  998616.56, Pred mean: 1021528.20\n",
      "  shampoos                       MAE:  257349.24, Actual mean:   59499.57, Pred mean:  302197.08\n",
      "  bathroom tissues               MAE:  248482.48, Actual mean:  844417.03, Pred mean:  906483.82\n",
      "  cookies                        MAE:  238740.21, Actual mean: 1467370.04, Pred mean: 1423721.78\n",
      "\n",
      "================================================================================\n",
      "RECOMMENDATIONS\n",
      "================================================================================\n",
      "\n",
      "Based on diagnostics above, try these fixes:\n",
      "\n",
      "1. REMOVE DIFFERENCING if series are short or heavily imputed:\n",
      "   TARGET_TRANSFORMS = []  # Remove Differences([1])\n",
      "\n",
      "2. REDUCE LAGS if many series are short:\n",
      "   LAGS = [1, 2, 4, 8, 13]  # Remove 26, 52\n",
      "\n",
      "3. FILTER OUT heavily imputed series (>30% imputed)\n",
      "\n",
      "4. CHECK if forward/backward fill is creating unrealistic patterns\n",
      "\n",
      "5. INCREASE min_child_samples for more regularization:\n",
      "   min_child_samples=50 or 100\n",
      "\n",
      "6. ADD more regularization:\n",
      "   reg_alpha=1.0, reg_lambda=1.0\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_74513/4220664284.py:129: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  series_mae = cv_df_eval.groupby('unique_id').apply(\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(\"=\"*80)\n",
    "print(\"PERFORMANCE DIAGNOSTICS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# 1. Check imputation impact\n",
    "print(\"\\n1. IMPUTATION ANALYSIS\")\n",
    "print(\"-\"*80)\n",
    "\n",
    "# Check what percentage of data was originally missing\n",
    "# This assumes train_df is your final densified/imputed dataset\n",
    "if 'train_df' in locals():\n",
    "    # Check series lengths - all should be equal after densification\n",
    "    series_lengths = train_df.groupby('unique_id').size()\n",
    "    print(f\"Series lengths after densification:\")\n",
    "    print(f\"  Min: {series_lengths.min()}, Max: {series_lengths.max()}\")\n",
    "    print(f\"  All equal: {len(series_lengths.unique()) == 1}\")\n",
    "    \n",
    "    # If you tracked NaNs before imputation, report it\n",
    "    # Otherwise, skip this section\n",
    "    print(\"\\n‚ö†Ô∏è  Note: Imputation percentage not tracked.\")\n",
    "    print(\"   If performance is poor, imputation may be the cause.\")\n",
    "\n",
    "# 2. Check training data quality\n",
    "print(\"\\n2. TRAINING DATA QUALITY\")\n",
    "print(\"-\"*80)\n",
    "\n",
    "if 'train_df' in locals():\n",
    "    print(f\"Training data shape: {train_df.shape}\")\n",
    "    print(f\"Unique series: {train_df['unique_id'].nunique()}\")\n",
    "    print(f\"Date range: {train_df['ds'].min()} to {train_df['ds'].max()}\")\n",
    "    \n",
    "    # Check for zero/near-zero values\n",
    "    zero_pct = (train_df['y'] == 0).sum() / len(train_df) * 100\n",
    "    near_zero_pct = (train_df['y'] < 1).sum() / len(train_df) * 100\n",
    "    print(f\"\\nZero values: {zero_pct:.1f}%\")\n",
    "    print(f\"Near-zero (<1): {near_zero_pct:.1f}%\")\n",
    "    \n",
    "    # Revenue distribution\n",
    "    print(f\"\\nRevenue distribution:\")\n",
    "    print(train_df['y'].describe())\n",
    "    \n",
    "    # Check for negative values\n",
    "    if (train_df['y'] < 0).any():\n",
    "        print(f\"‚ö†Ô∏è  WARNING: {(train_df['y'] < 0).sum()} negative values found!\")\n",
    "\n",
    "# 3. Check predictions quality\n",
    "print(\"\\n3. PREDICTION QUALITY ANALYSIS\")\n",
    "print(\"-\"*80)\n",
    "\n",
    "if 'cv_df_eval' in locals() and 'model_cols' in locals():\n",
    "    # Check for extreme predictions\n",
    "    for model_col in model_cols:\n",
    "        preds = cv_df_eval[model_col].dropna()\n",
    "        actuals = cv_df_eval['y'].dropna()\n",
    "        \n",
    "        print(f\"\\n{model_col}:\")\n",
    "        print(f\"  Predictions range: [{preds.min():.2f}, {preds.max():.2f}]\")\n",
    "        print(f\"  Actuals range: [{actuals.min():.2f}, {actuals.max():.2f}]\")\n",
    "        print(f\"  Predictions mean: {preds.mean():.2f} vs Actuals mean: {actuals.mean():.2f}\")\n",
    "        \n",
    "        # Check for negative predictions\n",
    "        neg_preds = (preds < 0).sum()\n",
    "        if neg_preds > 0:\n",
    "            print(f\"  ‚ö†Ô∏è  {neg_preds} negative predictions ({neg_preds/len(preds)*100:.1f}%)\")\n",
    "        \n",
    "        # Check for extreme predictions\n",
    "        extreme_high = (preds > actuals.quantile(0.99) * 2).sum()\n",
    "        if extreme_high > 0:\n",
    "            print(f\"  ‚ö†Ô∏è  {extreme_high} extremely high predictions\")\n",
    "\n",
    "# 4. Residual analysis\n",
    "print(\"\\n4. RESIDUAL ANALYSIS\")\n",
    "print(\"-\"*80)\n",
    "\n",
    "if 'cv_df_eval' in locals() and len(model_cols) > 0:\n",
    "    model_col = model_cols[0]  # Analyze first model\n",
    "    \n",
    "    mask = cv_df_eval[[model_col, 'y']].notna().all(axis=1)\n",
    "    actuals = cv_df_eval.loc[mask, 'y']\n",
    "    preds = cv_df_eval.loc[mask, model_col]\n",
    "    residuals = actuals - preds\n",
    "    \n",
    "    print(f\"Analyzing {model_col}:\")\n",
    "    print(f\"  Mean residual: {residuals.mean():.2f}\")\n",
    "    print(f\"  Median residual: {residuals.median():.2f}\")\n",
    "    print(f\"  Residual std: {residuals.std():.2f}\")\n",
    "    print(f\"  Mean absolute error: {np.abs(residuals).mean():.2f}\")\n",
    "    \n",
    "    # Check for systematic bias\n",
    "    if abs(residuals.mean()) > actuals.std() * 0.1:\n",
    "        print(f\"  ‚ö†Ô∏è  WARNING: Systematic bias detected!\")\n",
    "        if residuals.mean() > 0:\n",
    "            print(f\"     Model is UNDER-predicting on average\")\n",
    "        else:\n",
    "            print(f\"     Model is OVER-predicting on average\")\n",
    "\n",
    "# 5. Check differences transformation\n",
    "print(\"\\n5. DIFFERENCING IMPACT\")\n",
    "print(\"-\"*80)\n",
    "\n",
    "if 'TARGET_TRANSFORMS' in locals() and len(MLForecastHP().target_transforms) > 0:\n",
    "    print(f\"Target transforms applied: {MLForecastHP().target_transforms}\")\n",
    "    print(\"‚ö†Ô∏è  Differencing can cause issues if:\")\n",
    "    print(\"   - Series are short\")\n",
    "    print(\"   - Series have many imputed values\")\n",
    "    print(\"   - Series are already stationary\")\n",
    "    print(\"\\nüí° RECOMMENDATION: Try removing Differences([1]) and see if performance improves\")\n",
    "\n",
    "# 6. Check for data leakage\n",
    "print(\"\\n6. DATA LEAKAGE CHECK\")\n",
    "print(\"-\"*80)\n",
    "\n",
    "if 'cv_df_base' in locals():\n",
    "    # Check if CV is working correctly\n",
    "    cv_windows = cv_df_base.groupby(['unique_id', 'cutoff']).size()\n",
    "    print(f\"CV windows per series: {cv_windows.groupby(level=0).size().value_counts()}\")\n",
    "    \n",
    "    # Check cutoff dates\n",
    "    print(f\"\\nCutoff dates: {sorted(cv_df_base['cutoff'].unique())}\")\n",
    "\n",
    "# 7. Specific problematic series\n",
    "print(\"\\n7. WORST PERFORMING SERIES\")\n",
    "print(\"-\"*80)\n",
    "\n",
    "if 'cv_df_eval' in locals() and 'model_cols' in locals():\n",
    "    model_col = model_cols[0]\n",
    "    \n",
    "    # Calculate MAE per series\n",
    "    series_mae = cv_df_eval.groupby('unique_id').apply(\n",
    "        lambda x: mean_absolute_error(x['y'].dropna(), x[model_col].dropna()) \n",
    "        if len(x['y'].dropna()) > 0 else np.nan\n",
    "    ).sort_values(ascending=False)\n",
    "    \n",
    "    print(\"Top 10 worst series (by MAE):\")\n",
    "    for uid, mae in series_mae.head(10).items():\n",
    "        series_data = cv_df_eval[cv_df_eval['unique_id'] == uid]\n",
    "        actual_mean = series_data['y'].mean()\n",
    "        pred_mean = series_data[model_col].mean()\n",
    "        print(f\"  {uid:30s} MAE: {mae:>10.2f}, Actual mean: {actual_mean:>10.2f}, Pred mean: {pred_mean:>10.2f}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"RECOMMENDATIONS\")\n",
    "print(\"=\"*80)\n",
    "print(\"\"\"\n",
    "Based on diagnostics above, try these fixes:\n",
    "\n",
    "1. REMOVE DIFFERENCING if series are short or heavily imputed:\n",
    "   TARGET_TRANSFORMS = []  # Remove Differences([1])\n",
    "\n",
    "2. REDUCE LAGS if many series are short:\n",
    "   LAGS = [1, 2, 4, 8, 13]  # Remove 26, 52\n",
    "\n",
    "3. FILTER OUT heavily imputed series (>30% imputed)\n",
    "\n",
    "4. CHECK if forward/backward fill is creating unrealistic patterns\n",
    "\n",
    "5. INCREASE min_child_samples for more regularization:\n",
    "   min_child_samples=50 or 100\n",
    "\n",
    "6. ADD more regularization:\n",
    "   reg_alpha=1.0, reg_lambda=1.0\n",
    "\"\"\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "valuation",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
