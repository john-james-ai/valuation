{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "43cb608e",
   "metadata": {},
   "source": [
    "# LightGBM Model Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "623f8049",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "import wandb\n",
    "from typing import Tuple\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, mean_absolute_percentage_error\n",
    "\n",
    "from lightgbm import LGBMRegressor # The ML model\n",
    "from valuation.utils.metrics import compute_smape, compute_wape\n",
    "from hierarchicalforecast.core import HierarchicalReconciliation\n",
    "from hierarchicalforecast.methods import MinTrace\n",
    "from hierarchicalforecast.utils import aggregate\n",
    "from hierarchicalforecast.core import HierarchicalReconciliation\n",
    "from mlforecast import MLForecast\n",
    "from mlforecast.target_transforms import GlobalSklearnTransformer\n",
    "\n",
    "from valuation.infra.store.dataset import DatasetStore\n",
    "from valuation.asset.identity.dataset import DatasetID\n",
    "from valuation.core.stage import DatasetStage\n",
    "from valuation.asset.identity.model import ModelPassport\n",
    "from valuation.asset.model.mlforecast import MLForecastModel\n",
    "from valuation.infra.store.model import ModelStore\n",
    "from valuation.flow.modeling.model_selection.light_gbm import LightGBMHP\n",
    "from valuation.flow.modeling.model_selection.cv import CrossValidationHP\n",
    "from valuation.flow.modeling.model_selection.mlforecast import MLForecastHP\n",
    "from valuation.flow.modeling.model_selection.base import ModelParams\n",
    "\n",
    "# Suppress the specific warning\n",
    "warnings.filterwarnings('ignore', message='.*lag.*')\n",
    "warnings.filterwarnings('ignore', message='.*UnsupportedFieldAttributeWarning.*')\n",
    "wandb.login()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bc1866f",
   "metadata": {},
   "source": [
    "## Model Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74bcf1c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_CORES = 24              # Total CPU cores available\n",
    "# Reproducibility \n",
    "RANDOM_STATE = 42           # Fixed random seed\n",
    "\n",
    "MODELS = [LGBMRegressor(**LightGBMHP(tweedie_variance_power=1.2).as_dict()),\n",
    "          LGBMRegressor(**LightGBMHP(tweedie_variance_power=1.3).as_dict()),\n",
    "          LGBMRegressor(**LightGBMHP(tweedie_variance_power=1.4).as_dict()),\n",
    "          LGBMRegressor(**LightGBMHP(tweedie_variance_power=1.5).as_dict()),\n",
    "]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35da959f",
   "metadata": {},
   "source": [
    "## Training Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9ce279e",
   "metadata": {},
   "outputs": [],
   "source": [
    "store = DatasetStore()\n",
    "dataset_id = DatasetID(name=\"train_val\", stage=DatasetStage.MODEL)\n",
    "passport = store.get_passport(dataset_id=dataset_id)\n",
    "ds = store.get(passport=passport)\n",
    "train_df = ds.data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e206bd5",
   "metadata": {},
   "source": [
    "## Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3e68cb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "mf = MLForecast(models=MODELS,**MLForecastHP().as_dict())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88113e58",
   "metadata": {},
   "source": [
    "## Blocked Cross-Validation\n",
    "This generates the unreconciled forecasts for each fold. We must add fitted=True to get the in-sample forecasts for the reconciler."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be524319",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_df_base = mf.cross_validation(\n",
    "    df=train_df, **CrossValidationHP().as_dict())\n",
    "mf.fit(df=train_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e858377",
   "metadata": {},
   "source": [
    "## Create Summing Matrix and Tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9919aa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_summing_matrix(train_df: pd.DataFrame) -> Tuple:\n",
    "    # 1. Start with the core data (unique_id, ds, y)\n",
    "    hierarchy_df = train_df[['unique_id', 'ds', 'y']].drop_duplicates() \n",
    "\n",
    "    # 2. Create the grouping columns\n",
    "    hierarchy_df['store'] = hierarchy_df['unique_id'].apply(lambda s: s.split('_')[0])\n",
    "    hierarchy_df['category'] = hierarchy_df['unique_id'].apply(lambda s: s.split('_')[1])\n",
    "\n",
    "    # 3. Drop the 'unique_id' column from the input DF before aggregation\n",
    "    #    The aggregate function knows to use the combination of columns in 'spec'\n",
    "    #    to uniquely identify the time series levels.\n",
    "    hierarchy_df_clean = hierarchy_df.drop(columns=['unique_id']) # 👈 ADD THIS LINE\n",
    "\n",
    "    spec = [['store'], ['category'], ['store', 'category']]\n",
    "\n",
    "    # Pass the cleaned DataFrame to the aggregate function\n",
    "    return aggregate(df=hierarchy_df_clean, spec=spec)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a24b160d",
   "metadata": {},
   "source": [
    "## Aggregate Forecasts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16c822b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def aggregate_forecasts(cv_df_base: pd.DataFrame, spec: list) -> pd.DataFrame:\n",
    "    # Clean and Prepare Y_hat_df_base\n",
    "    Y_hat_df_base = cv_df_base.drop(columns=['cutoff', 'y'], errors='ignore')\n",
    "\n",
    "    # 1. Add the hierarchy columns to the base forecasts\n",
    "    Y_hat_df_base_clean = Y_hat_df_base.copy()\n",
    "    Y_hat_df_base_clean['store'] = Y_hat_df_base_clean['unique_id'].apply(lambda s: s.split('_')[0])\n",
    "    Y_hat_df_base_clean['category'] = Y_hat_df_base_clean['unique_id'].apply(lambda s: s.split('_')[1])\n",
    "\n",
    "    # 2. Identify the forecast column(s) - typically 'LGBMRegressor' or similar model name\n",
    "    forecast_col = 'LGBMRegressor'  # Adjust if your column has a different name\n",
    "\n",
    "    # 3. Rename forecast column to 'y' temporarily for aggregation\n",
    "    Y_hat_df_base_for_agg = Y_hat_df_base_clean.copy()\n",
    "    Y_hat_df_base_for_agg = Y_hat_df_base_for_agg.rename(columns={forecast_col: 'y'})\n",
    "    Y_hat_df_base_for_agg = Y_hat_df_base_for_agg.drop(columns=['unique_id'])\n",
    "\n",
    "    # 4. Aggregate to create forecasts at all hierarchy levels\n",
    "    Y_hat_aggregated, _, _ = aggregate(df=Y_hat_df_base_for_agg, spec=spec)\n",
    "\n",
    "    # 5. Rename back to original forecast column name\n",
    "    Y_hat_aggregated = Y_hat_aggregated.rename(columns={'y': forecast_col})\n",
    "\n",
    "    print(\"Forecasts aggregated successfully across all hierarchy levels.\")\n",
    "    print(f\"Base forecasts shape: {Y_hat_df_base.shape}\")\n",
    "    print(f\"Aggregated forecasts shape: {Y_hat_aggregated.shape}\")\n",
    "    print(f\"Unique IDs in aggregated forecasts: {Y_hat_aggregated['unique_id'].nunique()}\")\n",
    "    return Y_hat_aggregated\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75bc6e33",
   "metadata": {},
   "source": [
    "## Reconciler for CV Forecasts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cfff44e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def reconcile_forecasts(cv_df_base: pd.DataFrame, Y_hat_aggregated: pd.DataFrame, S_df: pd.DataFrame, tags: list) -> pd.DataFrame:\n",
    "        \n",
    "\n",
    "    # Initialize Hierarchical Reconciliation with MinTrace method\n",
    "    reconcilers = [MinTrace(method='ols')]\n",
    "    hrec = HierarchicalReconciliation(reconcilers=reconcilers)\n",
    "\n",
    "    # Prepare aggregated actuals\n",
    "    Y_df_base = cv_df_base[['unique_id', 'ds', 'y']].copy()\n",
    "    Y_df_base['store'] = Y_df_base['unique_id'].apply(lambda s: s.split('_')[0])\n",
    "    Y_df_base['category'] = Y_df_base['unique_id'].apply(lambda s: s.split('_')[1])\n",
    "    Y_df_base_for_agg = Y_df_base.drop(columns=['unique_id'])\n",
    "    Y_df_actuals, _, _ = aggregate(df=Y_df_base_for_agg, spec=spec)\n",
    "\n",
    "    # Reconcile (this adjusts the aggregated forecasts for coherence)\n",
    "    cv_df_reconciled = hrec.reconcile(\n",
    "        Y_hat_df=Y_hat_aggregated,  # Now has all hierarchy levels\n",
    "        Y_df=Y_df_actuals,\n",
    "        S_df=S_df,\n",
    "        tags=tags\n",
    "    )\n",
    "    return cv_df_reconciled"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1f42215",
   "metadata": {},
   "source": [
    "## Evaluate CV Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ad9ba1c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "39f6656b",
   "metadata": {},
   "source": [
    "## Model Performance Diagnosis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "295fa077",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print(\"=\"*80)\n",
    "print(\"PERFORMANCE DIAGNOSTICS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# 1. Check imputation impact\n",
    "print(\"\\n1. IMPUTATION ANALYSIS\")\n",
    "print(\"-\"*80)\n",
    "\n",
    "# Check what percentage of data was originally missing\n",
    "# This assumes train_df is your final densified/imputed dataset\n",
    "if 'train_df' in locals():\n",
    "    # Check series lengths - all should be equal after densification\n",
    "    series_lengths = train_df.groupby('unique_id').size()\n",
    "    print(f\"Series lengths after densification:\")\n",
    "    print(f\"  Min: {series_lengths.min()}, Max: {series_lengths.max()}\")\n",
    "    print(f\"  All equal: {len(series_lengths.unique()) == 1}\")\n",
    "    \n",
    "    # If you tracked NaNs before imputation, report it\n",
    "    # Otherwise, skip this section\n",
    "    print(\"\\n⚠️  Note: Imputation percentage not tracked.\")\n",
    "    print(\"   If performance is poor, imputation may be the cause.\")\n",
    "\n",
    "# 2. Check training data quality\n",
    "print(\"\\n2. TRAINING DATA QUALITY\")\n",
    "print(\"-\"*80)\n",
    "\n",
    "if 'train_df' in locals():\n",
    "    print(f\"Training data shape: {train_df.shape}\")\n",
    "    print(f\"Unique series: {train_df['unique_id'].nunique()}\")\n",
    "    print(f\"Date range: {train_df['ds'].min()} to {train_df['ds'].max()}\")\n",
    "    \n",
    "    # Check for zero/near-zero values\n",
    "    zero_pct = (train_df['y'] == 0).sum() / len(train_df) * 100\n",
    "    near_zero_pct = (train_df['y'] < 1).sum() / len(train_df) * 100\n",
    "    print(f\"\\nZero values: {zero_pct:.1f}%\")\n",
    "    print(f\"Near-zero (<1): {near_zero_pct:.1f}%\")\n",
    "    \n",
    "    # Revenue distribution\n",
    "    print(f\"\\nRevenue distribution:\")\n",
    "    print(train_df['y'].describe())\n",
    "    \n",
    "    # Check for negative values\n",
    "    if (train_df['y'] < 0).any():\n",
    "        print(f\"⚠️  WARNING: {(train_df['y'] < 0).sum()} negative values found!\")\n",
    "\n",
    "# 3. Check predictions quality\n",
    "print(\"\\n3. PREDICTION QUALITY ANALYSIS\")\n",
    "print(\"-\"*80)\n",
    "\n",
    "if 'cv_df_eval' in locals() and 'model_cols' in locals():\n",
    "    # Check for extreme predictions\n",
    "    for model_col in model_cols:\n",
    "        preds = cv_df_eval[model_col].dropna()\n",
    "        actuals = cv_df_eval['y'].dropna()\n",
    "        \n",
    "        print(f\"\\n{model_col}:\")\n",
    "        print(f\"  Predictions range: [{preds.min():.2f}, {preds.max():.2f}]\")\n",
    "        print(f\"  Actuals range: [{actuals.min():.2f}, {actuals.max():.2f}]\")\n",
    "        print(f\"  Predictions mean: {preds.mean():.2f} vs Actuals mean: {actuals.mean():.2f}\")\n",
    "        \n",
    "        # Check for negative predictions\n",
    "        neg_preds = (preds < 0).sum()\n",
    "        if neg_preds > 0:\n",
    "            print(f\"  ⚠️  {neg_preds} negative predictions ({neg_preds/len(preds)*100:.1f}%)\")\n",
    "        \n",
    "        # Check for extreme predictions\n",
    "        extreme_high = (preds > actuals.quantile(0.99) * 2).sum()\n",
    "        if extreme_high > 0:\n",
    "            print(f\"  ⚠️  {extreme_high} extremely high predictions\")\n",
    "\n",
    "# 4. Residual analysis\n",
    "print(\"\\n4. RESIDUAL ANALYSIS\")\n",
    "print(\"-\"*80)\n",
    "\n",
    "if 'cv_df_eval' in locals() and len(model_cols) > 0:\n",
    "    model_col = model_cols[0]  # Analyze first model\n",
    "    \n",
    "    mask = cv_df_eval[[model_col, 'y']].notna().all(axis=1)\n",
    "    actuals = cv_df_eval.loc[mask, 'y']\n",
    "    preds = cv_df_eval.loc[mask, model_col]\n",
    "    residuals = actuals - preds\n",
    "    \n",
    "    print(f\"Analyzing {model_col}:\")\n",
    "    print(f\"  Mean residual: {residuals.mean():.2f}\")\n",
    "    print(f\"  Median residual: {residuals.median():.2f}\")\n",
    "    print(f\"  Residual std: {residuals.std():.2f}\")\n",
    "    print(f\"  Mean absolute error: {np.abs(residuals).mean():.2f}\")\n",
    "    \n",
    "    # Check for systematic bias\n",
    "    if abs(residuals.mean()) > actuals.std() * 0.1:\n",
    "        print(f\"  ⚠️  WARNING: Systematic bias detected!\")\n",
    "        if residuals.mean() > 0:\n",
    "            print(f\"     Model is UNDER-predicting on average\")\n",
    "        else:\n",
    "            print(f\"     Model is OVER-predicting on average\")\n",
    "\n",
    "# 5. Check differences transformation\n",
    "print(\"\\n5. DIFFERENCING IMPACT\")\n",
    "print(\"-\"*80)\n",
    "\n",
    "if 'TARGET_TRANSFORMS' in locals() and len(MLForecastHP().target_transforms) > 0:\n",
    "    print(f\"Target transforms applied: {MLForecastHP().target_transforms}\")\n",
    "    print(\"⚠️  Differencing can cause issues if:\")\n",
    "    print(\"   - Series are short\")\n",
    "    print(\"   - Series have many imputed values\")\n",
    "    print(\"   - Series are already stationary\")\n",
    "    print(\"\\n💡 RECOMMENDATION: Try removing Differences([1]) and see if performance improves\")\n",
    "\n",
    "# 6. Check for data leakage\n",
    "print(\"\\n6. DATA LEAKAGE CHECK\")\n",
    "print(\"-\"*80)\n",
    "\n",
    "if 'cv_df_base' in locals():\n",
    "    # Check if CV is working correctly\n",
    "    cv_windows = cv_df_base.groupby(['unique_id', 'cutoff']).size()\n",
    "    print(f\"CV windows per series: {cv_windows.groupby(level=0).size().value_counts()}\")\n",
    "    \n",
    "    # Check cutoff dates\n",
    "    print(f\"\\nCutoff dates: {sorted(cv_df_base['cutoff'].unique())}\")\n",
    "\n",
    "# 7. Specific problematic series\n",
    "print(\"\\n7. WORST PERFORMING SERIES\")\n",
    "print(\"-\"*80)\n",
    "\n",
    "if 'cv_df_eval' in locals() and 'model_cols' in locals():\n",
    "    model_col = model_cols[0]\n",
    "    \n",
    "    # Calculate MAE per series\n",
    "    series_mae = cv_df_eval.groupby('unique_id').apply(\n",
    "        lambda x: mean_absolute_error(x['y'].dropna(), x[model_col].dropna()) \n",
    "        if len(x['y'].dropna()) > 0 else np.nan\n",
    "    ).sort_values(ascending=False)\n",
    "    \n",
    "    print(\"Top 10 worst series (by MAE):\")\n",
    "    for uid, mae in series_mae.head(10).items():\n",
    "        series_data = cv_df_eval[cv_df_eval['unique_id'] == uid]\n",
    "        actual_mean = series_data['y'].mean()\n",
    "        pred_mean = series_data[model_col].mean()\n",
    "        print(f\"  {uid:30s} MAE: {mae:>10.2f}, Actual mean: {actual_mean:>10.2f}, Pred mean: {pred_mean:>10.2f}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"RECOMMENDATIONS\")\n",
    "print(\"=\"*80)\n",
    "print(\"\"\"\n",
    "Based on diagnostics above, try these fixes:\n",
    "\n",
    "1. REMOVE DIFFERENCING if series are short or heavily imputed:\n",
    "   TARGET_TRANSFORMS = []  # Remove Differences([1])\n",
    "\n",
    "2. REDUCE LAGS if many series are short:\n",
    "   LAGS = [1, 2, 4, 8, 13]  # Remove 26, 52\n",
    "\n",
    "3. FILTER OUT heavily imputed series (>30% imputed)\n",
    "\n",
    "4. CHECK if forward/backward fill is creating unrealistic patterns\n",
    "\n",
    "5. INCREASE min_child_samples for more regularization:\n",
    "   min_child_samples=50 or 100\n",
    "\n",
    "6. ADD more regularization:\n",
    "   reg_alpha=1.0, reg_lambda=1.0\n",
    "\"\"\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "valuation",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
